import glob
import os.path
import xml.etree.ElementTree as ET
import json

import pandas as pd


class XmlParser:
    def __init__(self):
        self.content = []
        self.pers_names_footnotes = {}
        self.place_names_footnotes = {}

    def parse_xml(self, filepath):
        # create element tree object
        ET.XMLParser(encoding="utf-8")
        tree = ET.parse(filepath)
        root = tree.getroot()
        TEI_NAMESPACE = "http://www.tei-c.org/ns/1.0"

        # Iterate through the XML summary to get person and location names
        summary_tag = f"{{{TEI_NAMESPACE}}}summary"
        summary_element = root.find(f".//{summary_tag}")

        pers_names_summary = {}
        place_names_summary = {}

        if summary_element is not None:
            self.iterate_elements(summary_element, pers_names_summary, "persName", [])
            self.iterate_elements(summary_element, place_names_summary, "placeName", [])
        else:
            print("No summary found in the XML file.")

        # Iterate through the XML body to get person and location names
        body_tag = f"{{{TEI_NAMESPACE}}}body"
        body_element = root.find(f".//{body_tag}")

        pers_names_body = {}
        place_names_body = {}

        if body_element is not None:
            self.iterate_elements(body_element, pers_names_body, "persName", [])
            self.iterate_elements(body_element, place_names_body, "placeName", [])
        else:
            print("No body found in the XML file.")

        self.content = [pers_names_summary, place_names_summary, pers_names_body, place_names_body]
        return pers_names_summary, place_names_summary, pers_names_body, place_names_body

    def iterate_elements(self, element, dictionary, dict_type, ancestor_path):
        """Recursively iterate through XML elements and returns the body of a child element."""
        # Add current element to ancestor path
        current_path = ancestor_path + [element]

        for child in element:
            # Check if the child has children
            if self.has_children(child):
                # If the child has children, recursively call this function
                self.iterate_elements(child, dictionary, dict_type, current_path)

            # Check if the child is of the specified type
            elif child.tag[29:] in [dict_type]:
                try:
                    child.get("ref")
                except TypeError:
                    child.set("ref", "unknown")

                # Check if we're inside a footnote by examining the ancestor path
                inside_footnote = self.is_inside_footnote_with_path(current_path)

                # If inside a footnote, add to footnotes dictionary
                if inside_footnote:
                    if dict_type == "persName":
                        self.add_to_dictionary(self.pers_names_footnotes, child.text, child.get("ref"))
                    elif dict_type == "placeName":
                        self.add_to_dictionary(self.place_names_footnotes, child.text, child.get("ref"))

                # If not inside a footnote, add to the main dictionary
                else:
                    self.add_to_dictionary(dictionary, child.text, child.get("ref"))

    @staticmethod
    def is_inside_footnote_with_path(ancestor_path):
        """Check if any ancestor in the path is a footnote."""
        for ancestor in ancestor_path:
            if ancestor.get("type") == "footnote":
                return True
        return False

    @staticmethod
    def json_files_to_csv(filenames):
        df_columns = ["Filename", "summary_entities_found", "body_entities_found", "footnotes_entities_found", "distinct_summary_PersCount", "total_summary_PersCount",
                      "distinct_summary_PlaceCount", "total_summary_PlaceCount",
                      "distinct_body_PersCount", "total_body_PersCount",
                      "distinct_body_PlaceCount", "total_body_PlaceCount",
                      "distinct_footnotes_PersCount", "total_footnotes_PersCount",
                      "distinct_footnotes_PlaceCount", "total_footnotes_PlaceCount"]

        # Create dataframe with the specified columns
        df = pd.DataFrame(columns=df_columns)

        # Iterate through each file and extract the required information
        for filename in filenames:
            with open(filename, "r") as json_file:
                data = json.load(json_file)
                key = list(data.keys())[0]

                summary_pers_names = data[key]["summary"]["persNames"]
                summary_place_names = data[key]["summary"]["placeNames"]
                body_pers_names = data[key]["body"]["persNames"]
                body_place_names = data[key]["body"]["placeNames"]
                footnotes_pers_names = data[key]["footnotes"]["persNames"]
                footnotes_place_names = data[key]["footnotes"]["placeNames"]

                summary = True if len(summary_pers_names) + len(summary_place_names) > 0 else False
                body = True if len(body_pers_names) + len(body_place_names) > 0 else False
                footnotes = True if len(footnotes_pers_names) + len(footnotes_place_names) > 0 else False

                # Extract counts
                distinct_summary_pers_count = len(summary_pers_names)
                distinct_summary_place_count = len(summary_place_names)
                distinct_body_pers_count = len(body_pers_names)
                distinct_body_place_count = len(body_place_names)
                distinct_footnotes_pers_count = len(footnotes_pers_names)
                distinct_footnotes_place_count = len(footnotes_place_names)

                # Create a new row for the dataframe
                new_row = {
                    "Filename": key,
                    "summary_entities_found": summary,
                    "body_entities_found": body,
                    "footnotes_entities_found": footnotes,
                    "distinct_summary_PersCount": distinct_summary_pers_count,
                    "total_summary_PersCount": sum(info["count"] for info in summary_pers_names.values()),
                    "distinct_summary_PlaceCount": distinct_summary_place_count,
                    "total_summary_PlaceCount": sum(info["count"] for info in summary_place_names.values()),
                    "distinct_body_PersCount": distinct_body_pers_count,
                    "total_body_PersCount": sum(info["count"] for info in body_pers_names.values()),
                    "distinct_body_PlaceCount": distinct_body_place_count,
                    "total_body_PlaceCount": sum(info["count"] for info in body_place_names.values()),
                    "distinct_footnotes_PersCount": distinct_footnotes_pers_count,
                    "total_footnotes_PersCount": sum(info["count"] for info in footnotes_pers_names.values()),
                    "distinct_footnotes_PlaceCount": distinct_footnotes_place_count,
                    "total_footnotes_PlaceCount": sum(info["count"] for info in footnotes_place_names.values())
                }

                # Append the new row to the dataframe
                df = df._append(new_row, ignore_index=True)

        # Save the dataframe to an Excel file
        df.to_excel("Entities/summary_entities.xlsx", index=False)

    def save_entities_as_json(self, filepath):
        filename = os.path.basename(filepath).split('.')[0]

        data = {
            filename: {
                "summary": {
                    "persNames": self.content[0],
                    "placeNames": self.content[1]
                },
                "body": {
                    "persNames": self.content[2],
                    "placeNames": self.content[3]
                },
                "footnotes": {
                    "persNames": self.pers_names_footnotes,
                    "placeNames": self.place_names_footnotes
                }
            }
        }

        with open(f"Entities/{filename}_entities.json", "w", encoding="utf-8") as json_file:
            json.dump(data, json_file, indent=4)

    @staticmethod
    def has_children(element):
        """Check if an XML element has children."""
        return any(True for _ in element)

    @staticmethod
    def add_to_dictionary(dictionary, element, reference):
        """Add the body of an XML element to a dictionary."""
        if element in dictionary:
            dictionary[element]["count"] += 1
        else:
            dictionary[element] = {
                "ref": reference,
                "count": 1
            }

    @staticmethod
    def reverse_text_and_reference(dictionary):
        """Reverse the text and reference in the dictionary."""
        ref_dict = {}
        for name, value in dictionary.items():
            if value["ref"] in ref_dict:
                ref_dict[value["ref"]]["name"].append(name)
                ref_dict[value["ref"]]["count"] += value["count"]
            else:
                ref_dict[value["ref"]] = {
                    "name": [name],
                    "count": value["count"]
                }

        return ref_dict

    def print_content(self):
        print("Person Names in Summary:")
        for name, info in self.content[0].items():
            print(f"{name}: {info['count']} times, Reference: {info['ref']}")

        print("\nPlace Names in Summary:")
        for name, info in self.content[1].items():
            print(f"{name}: {info['count']} times, Reference: {info['ref']}")

        print("\nPerson Names in body:")
        for name, info in self.content[2].items():
            print(f"{name}: {info['count']} times, Reference: {info['ref']}")

        print("\nPlace Names in body:")
        for name, info in self.content[3].items():
            print(f"{name}: {info['count']} times, Reference: {info['ref']}")


if __name__ == "__main__":
    folder_path = "G:/Meine Ablage/ILU/OLD"
    filepath = "G:/Meine Ablage/ILU/OLD/1_OLD.xml"

    all_files = glob.glob(folder_path + "/*.xml")

    #for file in all_files:
    #    print(f"Processing file: {file}")
    #    parser = XmlParser()
    #    pers_names_summary, place_names_summary, pers_names_body, place_names_body = parser.parse_xml(file)
    #    # parser.print_content()
    #    parser.save_entities_as_json(file)

    files = glob.glob("G:/Meine Ablage/ILU/BullingerDigital/src/PreProcessing/Entities/*_entities.json")
    parser = XmlParser()
    parser.json_files_to_csv(files)
